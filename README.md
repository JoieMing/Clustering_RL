# Clustering_RL

## TODO
main.py for training and running PPO
save desired evaluation metrics:  
☑️ convergence reward vs episode  
☑️ best nmu, ari...  
☑️ the best nmu and ari shouldn't be reset  
☑️ MLP model (embedding) performance --- $\mathcal{L}_{F}$ every step
- the RL model is not converge
following:
- check the reward design: Is a higher reward received for the good cluster number
- check original code's convergence

The best
**NMI: 58.08053561066492, ARI: 52.96047128260229**
